{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moringa_Data_Science_Prep_W3_Independent_Project_2020_07_Gladwel_Wanjau_Python_Notebook",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3spE/xtCTZPo4JqoUuSUr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GladwelWanjau/Data-Science/blob/master/Moringa_Data_Science_Prep_W3_Independent_Project_2020_07_Gladwel_Wanjau_Python_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNW1lb2Z1QvH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7541761-b81d-43d7-8bb2-354534ad0530"
      },
      "source": [
        "#Importing all the data sets to my notebook\n",
        "#Importing the Libraries to be udes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data=pd.read_csv('Telcom_dataset.csv')#Importing the first file\n",
        "print(data)\n",
        "data1=pd.read_csv('Telcom_dataset2.csv')#Importing the second file\n",
        "print(data1)\n",
        "data2=pd.read_csv('Telcom_dataset3.csv')#Importing the third file\n",
        "print(data2)\n",
        "data3=pd.read_csv('cells_geo.csv')\n",
        "print(data3)\n",
        "data4=pd.read_excel('cells_geo_description.xlsx')#Importing the third File\n",
        "print(data4)\n",
        "data5=pd.read_excel('CDR_description.xlsx')# Imprting the fourth file\n",
        "print(data5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     PRODUTC  VALUE               DATETIME  ... COUNTRY_B     CELL_ID     SITE_ID\n",
            "0      Voice      0  2012-05-06 23:04:37.0  ...     19e2e  /TJNe+Mmtu  /TJNe+Mmtu\n",
            "1        sms      0  2012-05-06 23:05:25.0  ...     19e2e  /+cKZKIp41  /+cKZKIp41\n",
            "2        sms     25  2012-05-06 23:05:41.0  ...     19e2e  /u0FSD+ahi  /u0FSD+ahi\n",
            "3      Voice     56  2012-05-06 23:05:42.0  ...     19e2e  +cNeJzsTp3  +cNeJzsTp3\n",
            "4      Voice     14  2012-05-06 23:06:29.0  ...     19e2e  051KhYDCpv  051KhYDCpv\n",
            "...      ...    ...                    ...  ...       ...         ...         ...\n",
            "4996     sms    100  2012-05-07 00:01:54.0  ...     OTHER  0c2371d9bc  1e751d08a4\n",
            "4997   Voice      1  2012-05-07 00:01:54.0  ...     19e2e  5fb791cf56  65efe2bc62\n",
            "4998   Voice      0  2012-05-07 00:01:54.0  ...     19e2e  7773627c12  9ef9616350\n",
            "4999   Voice      0  2012-05-07 00:01:54.0  ...     19e2e  3f4af49d6c  969b8d0e39\n",
            "5000   Voice      7  2012-05-07 00:01:54.0  ...     19e2e  6f4d9b77a5  ebfc58af70\n",
            "\n",
            "[5001 rows x 10 columns]\n",
            "     PRODUCT  VALUE              DATE_TIME  ... COUNTRY_B     CELL_ID     SITE_ID\n",
            "0        sms      0  2012-05-07 23:02:06.0  ...     19e2e  +854AcBQT2  +854AcBQT2\n",
            "1      Voice      0  2012-05-07 23:03:44.0  ...     19e2e  +854AcBQT2  +854AcBQT2\n",
            "2        sms      0  2012-05-07 23:04:06.0  ...     19e2e  +laSrk7g6q  +laSrk7g6q\n",
            "3      Voice     37  2012-05-07 23:04:48.0  ...     19e2e  /xvRrCVKoQ  /xvRrCVKoQ\n",
            "4        sms     25  2012-05-07 23:04:58.0  ...     19e2e  +bO+qkSonO  +bO+qkSonO\n",
            "...      ...    ...                    ...  ...       ...         ...         ...\n",
            "4996     sms      0  2012-05-08 00:01:53.0  ...     19e2e  896459aace  b7d00e59e4\n",
            "4997     sms     25  2012-05-08 00:01:53.0  ...     19e2e  7e90b35166  211015b14d\n",
            "4998     sms      0  2012-05-08 00:01:53.0  ...     19e2e  fe70e431df  c7ea989264\n",
            "4999    data      0  2012-05-08 00:01:53.0  ...     OTHER  ffa6759bb2         NaN\n",
            "5000   Voice      0  2012-05-08 00:01:53.0  ...     19e2e  8630058aca  b47a998a3e\n",
            "\n",
            "[5001 rows x 10 columns]\n",
            "     PRODUCT  VALUE              DATE_TIME  ... COUNTRY_B      CELLID     SIET_ID\n",
            "0      Voice     61  2012-05-08 23:01:28.0  ...     19e2e  +38u2u/rfx  +38u2u/rfx\n",
            "1        sms      0  2012-05-08 23:01:31.0  ...     19e2e  +Fs4mTvdKx  +Fs4mTvdKx\n",
            "2      Voice     10  2012-05-08 23:02:59.0  ...     19e2e  +ZaaZozy/+  +ZaaZozy/+\n",
            "3        sms      0  2012-05-08 23:03:04.0  ...     19e2e  +cNeJzsTp3  +cNeJzsTp3\n",
            "4      Voice     22  2012-05-08 23:03:16.0  ...     19e2e  /eeMklgyJA  /eeMklgyJA\n",
            "...      ...    ...                    ...  ...       ...         ...         ...\n",
            "4996   Voice      0  2012-05-09 00:01:43.0  ...     19e2e  2aa04dcab7  f7d63a29e5\n",
            "4997   Voice     62  2012-05-09 00:01:43.0  ...     19e2e  7f1f2f889f  b4ddb9e93c\n",
            "4998   Voice     32  2012-05-09 00:01:43.0  ...     19e2e  a4731e780e  d68260ef50\n",
            "4999   Voice     30  2012-05-09 00:01:43.0  ...     19e2e  98ed726da2  b4130b54ab\n",
            "5000   Voice     60  2012-05-09 00:01:43.0  ...     19e2e  1c11a2fcbb  6d70dae094\n",
            "\n",
            "[5001 rows x 10 columns]\n",
            "     ;VILLES;STATUS;LOCALISATION;DECOUPZONE;ZONENAME;LONGITUDE;LATITUDE;REGION;AREA;CELL_ID;SITE_CODE\n",
            "0     0;ADJAME;In Service;ABIDJAN;\"\"\"Abidjan_EST\";AG...                                              \n",
            "1     1;ADJAME;In Service;ABIDJAN;\"\"\"Abidjan_EST\";AG...                                              \n",
            "2     2;ADJAME;In Service;ABIDJAN;\"\"\"Abidjan_EST\";AG...                                              \n",
            "3     3;ASSINIE;In Service;INTERIEUR;Grand-EST;\"ASSI...                                              \n",
            "4     4;ASSINIE;In Service;INTERIEUR;Grand-EST;\"ASSI...                                              \n",
            "...                                                 ...                                              \n",
            "3969  3969;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...                                              \n",
            "3970  3970;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...                                              \n",
            "3971  3971;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...                                              \n",
            "3972  3972;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...                                              \n",
            "3973  3973;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...                                              \n",
            "\n",
            "[3974 rows x 1 columns]\n",
            "     Column name                                        Description  Format\n",
            "0         VILLES                                               City  String\n",
            "1         STATUS                                  In Service or not  String\n",
            "2   LOCALISATION                                  in ABIDJAN or not  String\n",
            "3     DECOUPZONE                                  Geographical Zone  String\n",
            "4       ZONENAME                                       Name of Zone  String\n",
            "5      LONGITUDE                                          Longitude   Float\n",
            "6       LATITUDE                                           Latitude   Float\n",
            "7         REGION                                             Region  String\n",
            "8           AREA                                               Area  String\n",
            "9        CELL_ID                                     ID of the cell  String\n",
            "10     SITE_CODE  Site (there are several cells per site, severa...  String\n",
            "       Column name                                        Description   Format\n",
            "0          PRODUCT                                       Voice or SMS   String\n",
            "1            VALUE                                      Billing price  Integer\n",
            "2        DATE_TIME               Time in format yyyy-MM-dd hh:mm:ss.0   String\n",
            "3     CELL_ON_SITE  Which cell in the site was used (not needed here)  Integer\n",
            "4  DW_A_NUMBER_INT  Anonymized phone number of the person for whic...   String\n",
            "5  DW_B_NUMBER_INT        Anonymized phone number of the counterparty   String\n",
            "6        COUNTRY_A                  Country of party A (useless here)   String\n",
            "7        COUNTRY_B                  Country of party B (useless here)   String\n",
            "8          CELL_ID                                     ID of the cell   String\n",
            "9          SITE_ID                                     ID of the SITE   String\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00WIqKAgn5Vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Merging the Telcom_dataset\n",
        "import os\n",
        "import glob\n",
        "extension = 'csv'\n",
        "all_csv_files = [i for i in glob.glob('*.{}'.format(extension))]\n",
        "#combining all csv files in the list\n",
        "melted_csv = pd.concat([pd.read_csv(f) for f in Telcom_dataset.csv ])\n",
        "#exporting to csv\n",
        "melted_csv.to_csv( \"melted_csv.csv\", index=False, encoding='utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNgk5bfF-vIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "7ff3bbd9-62e1-4ebb-bfba-5c1d10c79745"
      },
      "source": [
        "#Creating a Dataframe from a csv file\n",
        "df=pd.read_csv('Telcom_dataset.csv',delimiter=',')#Importing the first file\n",
        "df\n",
        "df_1=pd.read_csv('Telcom_dataset2.csv',delimiter=',')#Importing the second file\n",
        "df_1\n",
        "df_2=pd.read_csv('Telcom_dataset3.csv',delimiter=',')#Importing the third file\n",
        "df_2\n",
        "df_3=pd.read_csv('cells_geo.csv',delimiter=',')#Importing the fourth file\n",
        "df_3"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>;VILLES;STATUS;LOCALISATION;DECOUPZONE;ZONENAME;LONGITUDE;LATITUDE;REGION;AREA;CELL_ID;SITE_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0;ADJAME;In Service;ABIDJAN;\"\"\"Abidjan_EST\";AG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1;ADJAME;In Service;ABIDJAN;\"\"\"Abidjan_EST\";AG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2;ADJAME;In Service;ABIDJAN;\"\"\"Abidjan_EST\";AG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3;ASSINIE;In Service;INTERIEUR;Grand-EST;\"ASSI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4;ASSINIE;In Service;INTERIEUR;Grand-EST;\"ASSI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3969</th>\n",
              "      <td>3969;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3970</th>\n",
              "      <td>3970;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3971</th>\n",
              "      <td>3971;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3972</th>\n",
              "      <td>3972;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3973</th>\n",
              "      <td>3973;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3974 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     ;VILLES;STATUS;LOCALISATION;DECOUPZONE;ZONENAME;LONGITUDE;LATITUDE;REGION;AREA;CELL_ID;SITE_CODE\n",
              "0     0;ADJAME;In Service;ABIDJAN;\"\"\"Abidjan_EST\";AG...                                              \n",
              "1     1;ADJAME;In Service;ABIDJAN;\"\"\"Abidjan_EST\";AG...                                              \n",
              "2     2;ADJAME;In Service;ABIDJAN;\"\"\"Abidjan_EST\";AG...                                              \n",
              "3     3;ASSINIE;In Service;INTERIEUR;Grand-EST;\"ASSI...                                              \n",
              "4     4;ASSINIE;In Service;INTERIEUR;Grand-EST;\"ASSI...                                              \n",
              "...                                                 ...                                              \n",
              "3969  3969;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...                                              \n",
              "3970  3970;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...                                              \n",
              "3971  3971;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...                                              \n",
              "3972  3972;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...                                              \n",
              "3973  3973;ZUENOULA;In Service;INTERIEUR;Grand-NORD;...                                              \n",
              "\n",
              "[3974 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7-euE0gt0JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Descriptive Statistics\n",
        "#For Day 1\n",
        "df['VALUE'].sum()  #Summing the value of the column.\n",
        "df['CELL_ON_SITE']\n",
        "df['PRODUCT'].describe()  # Describing the attributes of the column\n",
        "df['DATE_TIME'].describe()\n",
        "df['CELL_ON_SITE'].count()\n",
        "df['VALUE'].min()  #Finding the minimum value in the column\n",
        "df['DATE_TIME'].min()\n",
        "df['VALUE'].max()  #Finding the maximum value in the column\n",
        "df['DATE_TIME'].max()\n",
        "df['CELL_ON_SITE'].median() #Finding the Median\n",
        "df['VALUE'].median()\n",
        "df['VALUE'].var() # Finding the Variance\n",
        "df['CELL_ON_SITE'].var()\n",
        "df['VALUE'].std()  #Finding the Standard Deviation1\n",
        "df['CELL_ON_SITE'].std()\n",
        "df['VALUE'].skew() #Finding the skewness\n",
        "df['DATE_TIME'].skew()\n",
        "df['CELL_ON_SITE'].skew()\n",
        "df['VALUE'].kurt()   #Finding the Kurtosis\n",
        "df['DATE_TIME'].kurt()\n",
        "df['CELL_ON_SITE'].kurt()\n",
        "df.corr()\n",
        "#For Day 2\n",
        "df_1['VALUE'].sum()  #Summing the value of the column.\n",
        "df_1['CELL_ON_SITE']\n",
        "df_1['PRODUCT'].describe()  # Describing the attributes of the column\n",
        "df_1['DATE_TIME'].describe()\n",
        "df_1['CELL_ON_SITE'].count()\n",
        "df_1['VALUE'].min()  #Finding the minimum value in the column\n",
        "df_1['DATE_TIME'].min()\n",
        "df_1['VALUE'].max()  #Finding the maximum value in the column\n",
        "df_1['DATE_TIME'].max()\n",
        "df_1['CELL_ON_SITE'].median() #Finding the Median\n",
        "df_1['VALUE'].median()\n",
        "df_1['VALUE'].var() # Finding the Variance\n",
        "df_1['CELL_ON_SITE'].var()\n",
        "df_1['VALUE'].std()  #Finding the Standard Deviation\n",
        "df_1['CELL_ON_SITE'].std()\n",
        "df_1['VALUE'].skew() #Finding the skewness\n",
        "df_1['DATE_TIME'].skew()\n",
        "df_1['CELL_ON_SITE'].skew()\n",
        "df_1['VALUE'].kurt()   #Finding the Kurtosis\n",
        "df_1['DATE_TIME'].kurt()\n",
        "df_1['CELL_ON_SITE'].kurt()\n",
        "df_1.corr()\n",
        "#For Day 3\n",
        "df_2['VALUE'].sum()  #Summing the value of the column.\n",
        "df_2['CELL_ON_SITE']\n",
        "df_2['PRODUCT'].describe()  # Describing the attributes of the column\n",
        "df_2['DATE_TIME'].describe()\n",
        "df_2['CELL_ON_SITE'].count()\n",
        "df_2['VALUE'].min()  #Finding the minimum value in the column\n",
        "df_2['DATE_TIME'].min()\n",
        "df_2['VALUE'].max()  #Finding the maximum value in the column\n",
        "df_2['DATE_TIME'].max()\n",
        "df_2['CELL_ON_SITE'].median() #Finding the Median\n",
        "df_2['VALUE'].median()\n",
        "df_2['VALUE'].var() # Finding the Variance\n",
        "df_2['CELL_ON_SITE'].var()\n",
        "df_2['VALUE'].std()  #Finding the Standard Deviation\n",
        "df_2['CELL_ON_SITE'].std()\n",
        "df_2['VALUE'].skew() #Finding the skewness\n",
        "df_2['DATE_TIME'].skew()\n",
        "df_2['CELL_ON_SITE'].skew()\n",
        "df_2['VALUE'].kurt()   #Finding the Kurtosis\n",
        "df_2['DATE_TIME'].kurt()\n",
        "df_2['CELL_ON_SITE'].kurt()\n",
        "df_2.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYtT5eS4leMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Preparation\n",
        "#Merging Telcom_datasets with the Cells_geo data\n",
        "import pandas as pd\n",
        "df_4=df_3.merge(df_1, how='left', on='A')  # merges on column A of Telcom_dataset2\n",
        "df_4\n",
        "df_5=df_3.merge(df_2,how='left',on='A') # merges on column A of Telcom_dataset3\n",
        "df_5\n",
        "df_6=df_3.merge(df,how='left',on='A')# merges on column A of Telcom_dataset\n",
        "df_6\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEPROguFLTeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Question 1 \n",
        "#Finding out the most used city for the 3 days\n",
        "# step 1: viewing the two columns for each dataframe i.e.\n",
        "#For Day 2 \n",
        "df_7=df_4[(df_4['VILLES'] ) & (df_4['VALUE'] > 0)]\n",
        "#Sorting the two columns in an Ascending order to find out the most used cities\n",
        "df_7.sort_values(by='VALUE', ascending=1)\n",
        "#For Day 3\n",
        "df_8=df_5[(df_5['VILLES'] ) & (df_5['VALUE'] > 0)]\n",
        "#Sorting the two columns in an Ascending order to find out the mst used cities\n",
        "df_8.sort_values(by='VALUE', ascending=1)\n",
        "#For Day 1\n",
        "df_9=df_6[(df_6['VILLES'] ) & (df_6['VALUE'] > 0)]\n",
        "#Sorting the two columns in an Ascending order to find out the mst used cities\n",
        "df_9.sort_values(by='VALUE', ascending=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkR7KaQbO1HS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Question2\n",
        "#Finding out the most used cities for business hours and home hours\n",
        "#viewing the two columns for each dataframe i.e.\n",
        "#For Day 2\n",
        "df_10=df_4.loc ['VILLES':'DATE_TIME']\n",
        "#Sorting df_4\n",
        "df_10.sort_values(by='VALUE','DATE_TIME')\n",
        "#For Day 3\n",
        "df_11=df_5.loc['VILLES':'DATE_TIME']\n",
        "df_11.sort_values(by='VALUE','DATE_TIME')\n",
        "#For Day 1\n",
        "df_12=df_6.loc['VILLES':'DATE_TIME']\n",
        "df_12.sort_values(by='VALUE','DATE_TIME')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_C74uWPPHIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Question 3\n",
        "#Most used city for the 3 days\n",
        "#Merging the Telcom_dataset for the 3 days\n",
        "import os\n",
        "import glob\n",
        "extension = 'csv'\n",
        "all_csv_files = [i for i in glob.glob('*.{}'.format(extension))]\n",
        "#combining all csv files in the list\n",
        "melted_csv = pd.concat([pd.read_csv(f) for f in Telcom_dataset.csv ])\n",
        "#exporting to csv\n",
        "melted_csv.to_csv( \"melted_csv.csv\", index=False, encoding='utf-8-sig')\n",
        "#Alternatively\n",
        "df_merge_col=pd.merge(df_row,df_1,on 'df_2')\n",
        "df_merge_col\n",
        "#Merging the above with the cells_geo data\n",
        "df_13=df_3.merge(df_merge_col, how='left', on='A')  # merges on column A of Telcom_dataset\n",
        "df_13\n",
        "#Sorting the data to find the most used city\n",
        "df_13.sort_values(by='VALUE', ascending=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}